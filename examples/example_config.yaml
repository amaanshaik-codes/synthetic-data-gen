# SynthData Example Configuration
# ================================
# This is a comprehensive example showing all available options.
# Customize this file for your specific needs.

# Dataset name and description
name: "ecommerce_analytics_dataset"
description: "A realistic ecommerce dataset for practicing data analytics and machine learning"

# Business Context Configuration
# Defines the type of business being simulated
business_context:
  # Industry type: retail | ecommerce | fintech | healthcare | saas | manufacturing | marketing | logistics
  industry: ecommerce
  
  # Business model: b2b | b2c | d2c | marketplace | subscription
  business_model: b2c
  
  # Geographic scope: single-country | multi-country | global
  geography: multi-country
  
  # Number of months of historical data to generate
  time_span_months: 24
  
  # Countries to include (affects data localization)
  countries:
    - US
    - UK
    - DE

# Business Size Configuration
# Controls the scale of generated data
business_size:
  # Scale: startup | sme | enterprise
  scale: sme
  
  # Override defaults with specific numbers
  num_customers: 50000
  daily_transactions: 1500
  num_products: 1000
  num_employees: 200

# Data Quality Controls
# Configure intentional data issues for realistic practice
data_quality:
  # Missing values configuration
  missing_values:
    # Global missing rate (0.0 to 0.9)
    global_rate: 0.08
    
    # Per-column overrides
    per_column:
      phone: 0.20
      state: 0.15
      company_name: 0.30
    
    # Missing patterns: MCAR (completely random), MAR (depends on other cols), MNAR (depends on value)
    patterns:
      - MCAR
      - MAR
      - MNAR
    
    # Representations of null values to use
    null_representations:
      - ""
      - "NULL"
      - "N/A"
      - "None"
  
  # Duplicate records
  duplicates:
    rate: 0.02
    exact_duplicates: true
    near_duplicates: true
  
  # Data inconsistencies
  inconsistencies:
    date_formats: true
    currency_formats: true
    category_typos: true
    typo_rate: 0.03
    case_inconsistencies: true
    whitespace_issues: true
  
  # Outliers and anomalies
  outliers:
    rate: 0.03
    magnitude: 3.0
    outlier_types:
      - extreme_high
      - extreme_low
      - impossible_values
  
  # Noise injection
  noise:
    label_noise_rate: 0.02
    feature_noise_rate: 0.02
    noise_type: gaussian
  
  # Data drift over time
  data_drift:
    enabled: true
    drift_start_percentage: 0.7
    drift_magnitude: 0.2
    drift_type: gradual

# Difficulty Level
# easy | medium | hard | chaotic
# This applies presets to data quality settings above
difficulty: medium

# Analytics Configuration
# Configure for specific analytics/ML use cases
analytics:
  # Use case: descriptive | diagnostic | predictive | time-series | churn-prediction | fraud-detection | recommendation | segmentation | cohort-analysis
  use_case: churn-prediction
  
  # Target variable for ML
  target_variable: churned
  
  # Signal-to-noise ratio for target (0.1 to 1.0)
  signal_to_noise_ratio: 0.7
  
  # Enable feature leakage for educational purposes
  feature_leakage: false
  
  # Train/test split ratio
  train_test_split: 0.8
  
  # Use time-based split instead of random
  time_based_split: false
  
  # Use stratified split for classification
  stratified_split: true
  
  # Class imbalance ratio for the minority class
  class_imbalance_ratio: 0.15

# Output Configuration
output:
  # Format: csv | parquet | json | sql
  format: parquet
  
  # Output directory
  directory: "./output"
  
  # Include metadata files
  include_metadata: true
  include_data_dictionary: true
  include_quality_report: true
  include_suggested_questions: true
  
  # Compression (for parquet): gzip | snappy | none
  compression: snappy

# Reproducibility
reproducibility:
  # Random seed (null for random)
  seed: 42
  
  # Save config with output
  save_config: true
